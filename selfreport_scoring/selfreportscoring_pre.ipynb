{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de349143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n",
      "<ipython-input-4-eb438ebf3f61>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  AQ_clean[i] = AQ.loc[i]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(r\"%s\"%(os.getcwd()))\n",
    "# read in participant list\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "participants = pd.read_excel('%s/participantlist.xlsx'%(path.parent))\n",
    "participants = participants.loc[\n",
    "    participants['PhotosUploaded? (y/n)'] == 'y'].reset_index()\n",
    "participants = pd.DataFrame(data=participants['PROLIFIC_ID'])\n",
    "\n",
    "\n",
    "pretask_survey = '%s/' %(str(path.parent)) + [pretask for pretask in os.listdir(path.parent) if pretask.startswith('WTP_Pretask')][0]\n",
    "#read in raw qualtrics data\n",
    "alldata = pd.read_csv(pretask_survey)\n",
    "alldata = alldata.iloc[4:]\n",
    "alldata = alldata.sort_values(by=['Prolific_ID'])\n",
    "alldata.pop(\"attnchk\")  # remove attention checks\n",
    "alldata = alldata.reset_index()\n",
    "\n",
    "#columns list\n",
    "AQ_cols = [col for col in alldata.columns if 'AQ_' in col]\n",
    "AQ = alldata.filter(regex='AQ_|Prolific_ID')\n",
    "\n",
    "AQ_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(AQ)):\n",
    "    if AQ.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       AQ_clean[i] = AQ.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "AQ_clean = AQ_clean.transpose()\n",
    "AQ_clean = AQ_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = AQ_clean['Prolific_ID']\n",
    "AQ_clean = AQ_clean.drop(['index'], axis = 1)\n",
    "AQ_clean = AQ_clean.drop(['Prolific_ID'], axis = 1)\n",
    "AQ_clean= AQ_clean.astype(int)\n",
    "#%%\n",
    "AQ_score = pd.DataFrame(columns = AQ_clean.columns, index = AQ_clean.index)\n",
    "#%%\n",
    "\n",
    "#List of items to be reverse scored\n",
    "reverse_score= [2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]\n",
    "\n",
    "\n",
    "#Recode each response according to score rules\n",
    "for k in range(0,len(AQ_clean)):\n",
    "    for i in range (1,len(AQ_clean.columns)+1):\n",
    "\n",
    "        if i in reverse_score:\n",
    "            if AQ_clean.loc[k,'AQ_'+ str(i)] == 1 or AQ_clean.loc[k,'AQ_'+ str(i)] == 2:\n",
    "                AQ_score['AQ_' +str(i)][k] = 1\n",
    "            else:\n",
    "                AQ_score['AQ_'+str(i)][k] = 0\n",
    "        else:\n",
    "            if AQ_clean.loc[k,'AQ_'+ str(i)] == 3 or AQ_clean.loc[k,'AQ_'+ str(i)] == 4:\n",
    "                AQ_score['AQ_' +str(i)][k] = 1\n",
    "            else:\n",
    "                AQ_score['AQ_'+str(i)][k] = 0\n",
    "#%%\n",
    "AQ_score[\"AQ_score\"] = AQ_score.sum(axis=1)\n",
    "\n",
    "\n",
    "aq = pd.DataFrame()\n",
    "aq['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "aq['AQ']= AQ_score['AQ_score']\n",
    "aq.to_csv('%s/aq.csv' %(path.parent), index=False)\n",
    "#AQ_score[\"AQ_score\"].to_CSV('%/aq.csv')%(path.parent), index = False)\n",
    "#%%\n",
    "#selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "#selfreportdata['AQ'] = AQ_score[\"AQ_score\"]\n",
    "\n",
    "# aq=pd.DataFrame()\n",
    "# aq['AQ'] = AQ_score[\"AQ_score\"]\n",
    "# aq['AQ_score'].to_csv('%s/aq.csv' %(path.parent), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af317fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n",
      "<ipython-input-5-15dd709cd41e>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  BRCS_clean[i] = BRCS.loc[i]\n"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "BRCS_cols = [col for col in alldata.columns if 'BRCS_' in col]\n",
    "ProlificID_cols = [col for col in alldata.columns if 'Prolific_' in col]\n",
    "\n",
    "\n",
    "BRCS = alldata.filter(regex='BRCS_|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "BRCS_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(BRCS)):\n",
    "    if BRCS.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       BRCS_clean[i] = BRCS.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "BRCS_clean = BRCS_clean.transpose()\n",
    "BRCS_clean = BRCS_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = BRCS_clean['Prolific_ID']\n",
    "BRCS_clean = BRCS_clean.drop(['index'], axis = 1)\n",
    "BRCS_clean = BRCS_clean.drop(['Prolific_ID'], axis = 1)\n",
    "\n",
    "#%%\n",
    "BRCS_score = pd.DataFrame(columns = BRCS_clean.columns, index = BRCS_clean.index)\n",
    "\n",
    "for k in range(0,len(BRCS_clean)):\n",
    "    for i in range (0,len(BRCS_clean.columns)):\n",
    "        BRCS_score[BRCS_clean.columns[i]][k] = BRCS_clean.loc[k,BRCS_clean.columns[i]]\n",
    "        \n",
    "BRCS_score= BRCS_score.astype(int)\n",
    "BRCS_score[\"BRCS_total_score\"] = BRCS_score.sum(axis=1)\n",
    "\n",
    "#%%\n",
    "\n",
    "brcs = pd.DataFrame()\n",
    "brcs['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "brcs['BCRS_total_score']= BRCS_score[\"BRCS_total_score\"]\n",
    "brcs.to_csv('%s/brcs.csv' %(path.parent), index=False)\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['BRCS'] = BRCS_score[\"BRCS_total_score\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8406fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n",
      "<ipython-input-6-580677699632>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ERQ_clean[i] = ERQ.loc[i]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ERQ_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ERQ_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-580677699632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mERQ_cogreappraisal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mERQ_cogreappraisal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ERQ_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERQ_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ERQ_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mERQ_cogreappraisal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ERQ_3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERQ_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ERQ_12'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mERQ_cogreappraisal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ERQ_5'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERQ_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ERQ_14'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3804\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3804\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ERQ_1'"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "ERQ_cols = [col for col in alldata.columns if 'ERQ' in col]\n",
    "ProlificID_cols = [col for col in alldata.columns if 'Prolific_' in col]\n",
    "\n",
    "\n",
    "ERQ = alldata.filter(regex='ERQ_|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "ERQ_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(ERQ)):\n",
    "    if ERQ.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       ERQ_clean[i] = ERQ.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "ERQ_clean = ERQ_clean.transpose()\n",
    "ERQ_clean = ERQ_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = ERQ_clean['Prolific_ID']\n",
    "ERQ_clean = ERQ_clean.drop(['index'], axis = 1)\n",
    "ERQ_clean = ERQ_clean.drop(['Prolific_ID'], axis = 1)\n",
    "# %%\n",
    "ERQ_score = pd.DataFrame(columns = ERQ_clean.columns, index = ERQ_clean.index)\n",
    "\n",
    "#%%\n",
    "ERQ_cogreappraisal = pd.DataFrame()\n",
    "\n",
    "ERQ_cogreappraisal['ERQ_1'] = ERQ_clean['ERQ_1']\n",
    "ERQ_cogreappraisal['ERQ_3'] = ERQ_clean['ERQ_12']\n",
    "ERQ_cogreappraisal['ERQ_5'] = ERQ_clean['ERQ_14']\n",
    "ERQ_cogreappraisal['ERQ_7'] = ERQ_clean['ERQ_16']\n",
    "ERQ_cogreappraisal['ERQ_8'] = ERQ_clean['ERQ_17']\n",
    "ERQ_cogreappraisal['ERQ_10'] = ERQ_clean['ERQ_19']\n",
    "\n",
    "ERQ_cogreappraisal= ERQ_cogreappraisal.astype(int)\n",
    "ERQ_cogreappraisal[\"ERQ_cogreappraisal\"] = ERQ_cogreappraisal.sum(axis=1)/6\n",
    "\n",
    "#%%\n",
    "\n",
    "ERQ_emosuppression = pd.DataFrame()\n",
    "ERQ_emosuppression['ERQ_2'] = ERQ_clean['ERQ_11']\n",
    "ERQ_emosuppression['ERQ_4'] = ERQ_clean['ERQ_13']\n",
    "ERQ_emosuppression['ERQ_6'] = ERQ_clean['ERQ_15']\n",
    "ERQ_emosuppression['ERQ_9'] = ERQ_clean['ERQ_18']\n",
    "\n",
    "\n",
    "ERQ_emosuppression= ERQ_emosuppression.astype(int)\n",
    "ERQ_emosuppression[\"ERQ_emosuppression\"] = ERQ_emosuppression.sum(axis=1)/4\n",
    "\n",
    "#%%\n",
    "\n",
    "erq = pd.DataFrame()\n",
    "erq['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "erq['ERQ_emosuppression']= ERQ_emosuppression[\"ERQ_emosuppression\"]\n",
    "erq['ERQ_cogreappraisal'] = ERQ_cogreappraisal[\"ERQ_cogreappraisal\"]\n",
    "erq.to_csv('%s/erq.csv' %(path.parent), index=False)\n",
    "\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['ERQ_emosuppression'] = ERQ_emosuppression[\"ERQ_emosuppression\"]\n",
    "# selfreportdata['ERQ_cogreappraisal'] = ERQ_cogreappraisal[\"ERQ_cogreappraisal\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1bdd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n",
      "<ipython-input-7-703561da6560>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  NTBS_clean[i] = NTBS.loc[i]\n"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "NTBS_cols = [col for col in alldata.columns if 'NTBS' in col]\n",
    "ProlificID_cols = [col for col in alldata.columns if 'Prolific_' in col]\n",
    "\n",
    "\n",
    "NTBS = alldata.filter(regex='NTBS|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "NTBS_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(NTBS)):\n",
    "    if NTBS.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       NTBS_clean[i] = NTBS.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "NTBS_clean = NTBS_clean.transpose()\n",
    "NTBS_clean = NTBS_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = NTBS_clean['Prolific_ID']\n",
    "NTBS_clean = NTBS_clean.drop(['index'], axis = 1)\n",
    "NTBS_clean = NTBS_clean.drop(['Prolific_ID'], axis = 1)\n",
    "# %%\n",
    "NTBS_score = pd.DataFrame(columns = NTBS_clean.columns, index = NTBS_clean.index)\n",
    "\n",
    "for k in range(0,len(NTBS_clean)):\n",
    "    for i in range (0,len(NTBS_clean.columns)):\n",
    "        NTBS_score[NTBS_clean.columns[i]][k] = NTBS_clean.loc[k,NTBS_clean.columns[i]]\n",
    "        \n",
    "NTBS_score= NTBS_score.astype(int)\n",
    "NTBS_score[\"NTBS\"] = NTBS_score.sum(axis=1)\n",
    "#%%\n",
    "ntbs = pd.DataFrame()\n",
    "ntbs['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "ntbs['NTBS_score']= NTBS_score[\"NTBS\"]\n",
    "ntbs.to_csv('%s/ntbs.csv' %(path.parent), index=False)\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['NTBS'] = NTBS_score[\"NTBS\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8e6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n",
      "<ipython-input-9-843a39f9cfad>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  PSS_clean[i] = PSS.loc[i]\n"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "PSS_cols = [col for col in alldata.columns if 'PerceivedStress_' in col]\n",
    "PSS = alldata.filter(regex='PerceivedStress_|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "PSS_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(PSS)):\n",
    "    if PSS.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       PSS_clean[i] = PSS.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "PSS_clean = PSS_clean.transpose()\n",
    "PSS_clean = PSS_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = PSS_clean['Prolific_ID']\n",
    "PSS_clean = PSS_clean.drop(['index'], axis = 1)\n",
    "PSS_clean = PSS_clean.drop(['Prolific_ID'], axis = 1)\n",
    "PSS_clean= PSS_clean.astype(int)\n",
    "#%%\n",
    "PSS_score = pd.DataFrame(columns = PSS_clean.columns, index = PSS_clean.index)\n",
    "#%%\n",
    "reverse_score= [4, 5, 7, 8,]\n",
    "\n",
    "for k in range(0,len(PSS_clean)):\n",
    "    for i in range (1,len(PSS_clean.columns)+1):\n",
    "        if i in reverse_score:\n",
    "            if PSS_clean.loc[k,'PerceivedStress_' + str(i)] == 4:\n",
    "                PSS_score['PerceivedStress_' + str(i)][k] = 0\n",
    "            elif PSS_clean.loc[k,'PerceivedStress_' + str(i)] == 3:\n",
    "                PSS_score['PerceivedStress_' + str(i)][k] = 1\n",
    "            elif PSS_clean.loc[k,'PerceivedStress_' + str(i)] == 2:\n",
    "                PSS_score['PerceivedStress_' + str(i)][k] = 2\n",
    "            elif PSS_clean.loc[k,'PerceivedStress_' + str(i)] == 1:\n",
    "                PSS_score['PerceivedStress_' + str(i)][k] = 3\n",
    "            elif PSS_clean.loc[k,'PerceivedStress_' + str(i)] == 0:\n",
    "                PSS_score['PerceivedStress_' + str(i)][k] = 4\n",
    "        else:\n",
    "            PSS_score['PerceivedStress_' +str(i)][k] = PSS_clean.loc[k,'PerceivedStress_'+ str(i)]\n",
    "PSS_score= PSS_score.astype(int)\n",
    "#%%\n",
    "PSS_score[\"PSS_score\"] = PSS_score.sum(axis=1)\n",
    "#%%\n",
    "pss = pd.DataFrame()\n",
    "pss['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "pss[\"PSS_score\"]= PSS_score[\"PSS_score\"]\n",
    "pss.to_csv('%s/pss.csv' %(path.parent), index=False)\n",
    "\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['PSS'] = PSS_score[\"PSS_score\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2ffc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n",
      "<ipython-input-10-a9b153dc4cd3>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  RSQ_clean[i] = RSQ.loc[i]\n"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "RSQ_cols = [col for col in alldata.columns if 'RSQ_' in col]\n",
    "ProlificID_cols = [col for col in alldata.columns if 'Prolific_' in col]\n",
    "\n",
    "\n",
    "RSQ = alldata.filter(regex='RSQ_|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "RSQ_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(RSQ)):\n",
    "    if RSQ.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       RSQ_clean[i] = RSQ.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "RSQ_clean = RSQ_clean.transpose()\n",
    "RSQ_clean = RSQ_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = RSQ_clean['Prolific_ID']\n",
    "RSQ_clean = RSQ_clean.drop(['index'], axis = 1)\n",
    "RSQ_clean = RSQ_clean.drop(['Prolific_ID'], axis = 1)\n",
    "\n",
    "#%%\n",
    "RSQ_score = pd.DataFrame(columns = RSQ_clean.columns, index = RSQ_clean.index)\n",
    "reverse_score = [col for col in RSQ_clean.columns if 'b' in col]\n",
    "noreverse_score = [col for col in RSQ_clean.columns if 'a' in col]\n",
    "\n",
    "for k in range(0,len(RSQ_clean)):\n",
    "    for i in range (0,len(RSQ_clean.columns)):\n",
    "\n",
    "        if RSQ_clean.columns[i] in reverse_score:\n",
    "            if RSQ_clean.loc[k,RSQ_clean.columns[i]] == '6':\n",
    "                RSQ_score[RSQ_clean.columns[i]][k] = 1\n",
    "            elif RSQ_clean.loc[k,RSQ_clean.columns[i]] == '5':\n",
    "                RSQ_score[RSQ_clean.columns[i]][k] = 2\n",
    "            elif RSQ_clean.loc[k,RSQ_clean.columns[i]] == '4':\n",
    "                RSQ_score[RSQ_clean.columns[i]][k] = 3\n",
    "            elif RSQ_clean.loc[k,RSQ_clean.columns[i]] == '3':\n",
    "                RSQ_score[RSQ_clean.columns[i]][k] = 4\n",
    "            elif RSQ_clean.loc[k,RSQ_clean.columns[i]] == '2':\n",
    "                RSQ_score[RSQ_clean.columns[i]][k] = 5\n",
    "            elif RSQ_clean.loc[k,RSQ_clean.columns[i]] == '1':\n",
    "                RSQ_score[RSQ_clean.columns[i]][k] = 6\n",
    "        else:\n",
    "            RSQ_score[RSQ_clean.columns[i]][k] = RSQ_clean.loc[k,RSQ_clean.columns[i]]\n",
    "\n",
    "RSQ_score= RSQ_score.astype(int)\n",
    "#%%\n",
    "RSQ_average = pd.DataFrame()\n",
    "\n",
    "RSQ_average['RS_1'] = RSQ_score['RSQ_1a']* RSQ_score['RSQ_1b']\n",
    "RSQ_average['RS_2'] = RSQ_score['RSQ_2a']* RSQ_score['RSQ_2b']\n",
    "RSQ_average['RS_3'] = RSQ_score['RSQ_3a']* RSQ_score['RSQ_3b']\n",
    "RSQ_average['RS_4'] = RSQ_score['RSQ_4a']* RSQ_score['RSQ_4b']\n",
    "RSQ_average['RS_5'] = RSQ_score['RSQ_5a']* RSQ_score['RSQ_5b']\n",
    "RSQ_average['RS_6'] = RSQ_score['RSQ_6a']* RSQ_score['RSQ_6b']\n",
    "RSQ_average['RS_7'] = RSQ_score['RSQ_7a']* RSQ_score['RSQ_7b']\n",
    "RSQ_average['RS_8'] = RSQ_score['RSQ_8a']* RSQ_score['RSQ_8b']\n",
    "\n",
    "RSQ_average['RSQ_finalscore'] = RSQ_average.sum(axis=1)/8\n",
    "#%%\n",
    "\n",
    "rsq = pd.DataFrame()\n",
    "rsq['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "rsq[\"RSQ_finalscore\"]= RSQ_average['RSQ_finalscore']\n",
    "rsq.to_csv('%s/rsq.csv' %(path.parent), index=False)\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['RSQ'] = RSQ_average[\"RSQ_finalscore\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e0f663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n",
      "<ipython-input-11-a580bf573ecb>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SCS_clean[i] = SCS.loc[i]\n"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "SCS_cols = [col for col in alldata.columns if 'SCS_' in col]\n",
    "SCS = alldata.filter(regex='SCS_|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "SCS_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(SCS)):\n",
    "    if SCS.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       SCS_clean[i] = SCS.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "SCS_clean = SCS_clean.transpose()\n",
    "SCS_clean = SCS_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = SCS_clean['Prolific_ID']\n",
    "SCS_clean = SCS_clean.drop(['index'], axis = 1)\n",
    "SCS_clean = SCS_clean.drop(['Prolific_ID'], axis = 1)\n",
    "SCS_clean= SCS_clean.astype(int)\n",
    "#%%\n",
    "SCS_score = pd.DataFrame(columns = SCS_clean.columns, index = SCS_clean.index)\n",
    "#%%\n",
    "reverse_score = [1, 2, 3, 4, 5, 6, 8, 10, 15, 18]\n",
    "\n",
    "for k in range(0,len(SCS_clean)):\n",
    "    for i in range (1,len(SCS_clean.columns)+1):\n",
    "        if i in reverse_score:\n",
    "            if SCS_clean.loc[k,'SCS_' + str(i)] == 6:\n",
    "                SCS_score['SCS_' + str(i)][k] = 1\n",
    "            elif SCS_clean.loc[k,'SCS_' + str(i)] == 5:\n",
    "                SCS_score['SCS_' + str(i)][k] = 2\n",
    "            elif SCS_clean.loc[k,'SCS_' + str(i)] == 4:\n",
    "                SCS_score['SCS_' + str(i)][k] = 3\n",
    "            elif SCS_clean.loc[k,'SCS_' + str(i)] == 3:\n",
    "                SCS_score['SCS_' + str(i)][k] = 4\n",
    "            elif SCS_clean.loc[k,'SCS_' + str(i)] == 2:\n",
    "                SCS_score['SCS_' + str(i)][k] = 5\n",
    "            elif SCS_clean.loc[k,'SCS_' + str(i)] == 1:\n",
    "                SCS_score['SCS_' + str(i)][k] = 6\n",
    "        else:\n",
    "            SCS_score['SCS_' +str(i)][k] = SCS_clean.loc[k,'SCS_'+ str(i)]\n",
    "\n",
    "SCS_score= SCS_score.astype(int)\n",
    "\n",
    "        \n",
    "SCS_score= SCS_score.astype(int)\n",
    "SCS_score[\"SCS_score\"] = SCS_score.sum(axis=1)\n",
    "#%%\n",
    "scs = pd.DataFrame()\n",
    "scs['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "scs[\"SCS_score\"]= SCS_score[\"SCS_score\"]\n",
    "scs.to_csv('%s/scs.csv' %(path.parent), index=False)\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['SCS'] = SCS_score[\"SCS_score\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc285db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n",
      "<ipython-input-12-8efe1cdc5e0d>:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRQ_clean[i] = SRQ.loc[i]\n"
     ]
    }
   ],
   "source": [
    "#columns list\n",
    "SRQ_cols = [col for col in alldata.columns if 'SRQ' in col]\n",
    "ProlificID_cols = [col for col in alldata.columns if 'Prolific_' in col]\n",
    "\n",
    "\n",
    "SRQ = alldata.filter(regex='SRQ_|Prolific_ID')\n",
    "\n",
    "\n",
    "# %%\n",
    "SRQ_clean = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(SRQ)):\n",
    "    if SRQ.loc[i,'Prolific_ID'] in participants['PROLIFIC_ID'].values:\n",
    "       SRQ_clean[i] = SRQ.loc[i]    \n",
    "\n",
    "finaldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "SRQ_clean = SRQ_clean.transpose()\n",
    "SRQ_clean = SRQ_clean.reset_index()\n",
    "finaldata['Prolific_ID'] = SRQ_clean['Prolific_ID']\n",
    "SRQ_clean = SRQ_clean.drop(['index'], axis = 1)\n",
    "SRQ_clean = SRQ_clean.drop(['Prolific_ID'], axis = 1)\n",
    "SRQ_clean = SRQ_clean.fillna(0)\n",
    "#%%\n",
    "\n",
    "SRQ_admiration = pd.DataFrame()\n",
    "\n",
    "SRQ_admiration['SRQ_1'] = SRQ_clean['SRQ_1']\n",
    "SRQ_admiration['SRQ_7'] = SRQ_clean['SRQ_7']\n",
    "SRQ_admiration['SRQ_11'] = SRQ_clean['SRQ_11']\n",
    "SRQ_admiration['SRQ_18'] = SRQ_clean['SRQ_18']\n",
    "\n",
    "\n",
    "SRQ_admiration= SRQ_admiration.astype(int)\n",
    "SRQ_admiration[\"SRQ_admiration\"] = SRQ_admiration.sum(axis=1)/4\n",
    "\n",
    "#%%\n",
    "\n",
    "SRQ_negsocpot = pd.DataFrame()\n",
    "\n",
    "SRQ_negsocpot['SRQ_3'] = SRQ_clean['SRQ_3']\n",
    "SRQ_negsocpot['SRQ_5'] = SRQ_clean['SRQ_5']\n",
    "SRQ_negsocpot['SRQ_8'] = SRQ_clean['SRQ_8']\n",
    "SRQ_negsocpot['SRQ_14'] = SRQ_clean['SRQ_14']\n",
    "SRQ_negsocpot['SRQ_17'] = SRQ_clean['SRQ_17']\n",
    "\n",
    "\n",
    "SRQ_negsocpot= SRQ_negsocpot.astype(int)\n",
    "SRQ_negsocpot[\"SRQ_negsocpot\"] = SRQ_negsocpot.sum(axis=1)/5\n",
    "\n",
    "#%%\n",
    "\n",
    "SRQ_passivity = pd.DataFrame()\n",
    "\n",
    "SRQ_passivity['SRQ_12'] = SRQ_clean['SRQ_12']\n",
    "SRQ_passivity['SRQ_21'] = SRQ_clean['SRQ_21']\n",
    "SRQ_passivity['SRQ_23'] = SRQ_clean['SRQ_23']\n",
    "\n",
    "SRQ_passivity= SRQ_passivity.astype(int)\n",
    "SRQ_passivity[\"SRQ_passivity\"] = SRQ_passivity.sum(axis=1)/3\n",
    "\n",
    "#%%\n",
    "\n",
    "SRQ_prosocint = pd.DataFrame()\n",
    "\n",
    "SRQ_prosocint['SRQ_2'] = SRQ_clean['SRQ_2']\n",
    "SRQ_prosocint['SRQ_6'] = SRQ_clean['SRQ_6']\n",
    "SRQ_prosocint['SRQ_16'] = SRQ_clean['SRQ_16']\n",
    "SRQ_prosocint['SRQ_19'] = SRQ_clean['SRQ_19']\n",
    "SRQ_prosocint['SRQ_22'] = SRQ_clean['SRQ_22']\n",
    "\n",
    "\n",
    "SRQ_prosocint= SRQ_prosocint.astype(int)\n",
    "SRQ_prosocint[\"SRQ_prosocint\"] = SRQ_prosocint.sum(axis=1)/5\n",
    "\n",
    "#%%\n",
    "\n",
    "SRQ_sexrel = pd.DataFrame()\n",
    "\n",
    "SRQ_sexrel['SRQ_9'] = SRQ_clean['SRQ_9']\n",
    "SRQ_sexrel['SRQ_13'] = SRQ_clean['SRQ_13']\n",
    "SRQ_sexrel['SRQ_20'] = SRQ_clean['SRQ_20']\n",
    "\n",
    "SRQ_sexrel= SRQ_sexrel.astype(int)\n",
    "SRQ_sexrel[\"SRQ_sexrel\"] = SRQ_sexrel.sum(axis=1)/3\n",
    "\n",
    "#%%\n",
    "\n",
    "SRQ_sociability = pd.DataFrame()\n",
    "\n",
    "SRQ_sociability['SRQ_4'] = SRQ_clean['SRQ_4']\n",
    "SRQ_sociability['SRQ_10'] = SRQ_clean['SRQ_10']\n",
    "SRQ_sociability['SRQ_15'] = SRQ_clean['SRQ_15']\n",
    "\n",
    "SRQ_sociability= SRQ_sociability.astype(int)\n",
    "SRQ_sociability[\"SRQ_sociability\"] = SRQ_sociability.sum(axis=1)/3\n",
    "\n",
    "#%%\n",
    "\n",
    "srq = pd.DataFrame()\n",
    "srq['Prolific_ID'] = finaldata['Prolific_ID']\n",
    "srq[\"SRQ_admiration\"]= SRQ_admiration[\"SRQ_admiration\"]\n",
    "srq['SRQ_negsocpot'] = SRQ_negsocpot[\"SRQ_negsocpot\"]\n",
    "srq['SRQ_prosocint'] = SRQ_prosocint[\"SRQ_prosocint\"]\n",
    "srq['SRQ_sexrel'] = SRQ_sexrel[\"SRQ_sexrel\"]\n",
    "srq['SRQ_sociability'] = SRQ_sociability[\"SRQ_sociability\"]\n",
    "srq.to_csv('%s/srq.csv' %(path.parent), index=False)\n",
    "\n",
    "\n",
    "# selfreportdata = pd.read_csv('%s/selfreportdata_master_DF.csv' %(path.parent))\n",
    "# selfreportdata['SRQ_admiration'] = SRQ_admiration[\"SRQ_admiration\"]\n",
    "# selfreportdata['SRQ_negsocpot'] = SRQ_negsocpot[\"SRQ_negsocpot\"]\n",
    "# selfreportdata['SRQ_prosocint'] = SRQ_prosocint[\"SRQ_prosocint\"]\n",
    "# selfreportdata['SRQ_sexrel'] = SRQ_sexrel[\"SRQ_sexrel\"]\n",
    "# selfreportdata['SRQ_sociability'] = SRQ_sociability[\"SRQ_sociability\"]\n",
    "# selfreportdata.to_csv('%s/selfreportdata_master_DF.csv' %(path.parent), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863475f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
